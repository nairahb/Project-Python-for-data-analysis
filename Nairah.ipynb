{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HAPT Recognition project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loading of the data is done.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.metrics import coverage_error, label_ranking_average_precision_score\n",
    "\n",
    "X_train = np.loadtxt('HAPT Data Set/Train/X_train.txt', delimiter=' ')\n",
    "Y_train = np.loadtxt('HAPT Data Set/Train/y_train.txt')\n",
    "\n",
    "X_test = np.loadtxt('HAPT Data Set/Test/X_test.txt', delimiter=' ')\n",
    "Y_test = np.loadtxt('HAPT Data Set/Test/y_test.txt')\n",
    "\n",
    "print(\"The loading of the data is done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the training data is  (7767, 561) (7767,)\n",
      "The shape of the test data is  (3162, 561) (3162,)\n"
     ]
    }
   ],
   "source": [
    "print(\"The shape of the training data is \", X_train.shape, Y_train.shape)\n",
    "print(\"The shape of the test data is \", X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 7767 samples decribed by 561 features in the training dataset while we have 3162 described by 561 features in the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7767 entries, 0 to 7766\n",
      "Columns: 561 entries, 0 to 560\n",
      "dtypes: float64(561)\n",
      "memory usage: 33.2 MB\n"
     ]
    }
   ],
   "source": [
    "X_train_df = pd.DataFrame(X_train) # To transform the numpy array to a pandas DataFrame\n",
    "X_train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that all the features are continuous. No need to perform pre-processing specific to categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The labels are [ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] totaling a number of labels 12\n"
     ]
    }
   ],
   "source": [
    "print(\"The labels are {} totaling a number of labels {}\".format(np.unique(Y_train), len(np.unique(Y_train))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us look at the labels' distribution, to see if a weighting is necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2299.,  987., 1293., 1423., 1413.,   47.,   23.,   75.,   60.,\n",
       "         147.]),\n",
       " array([ 1. ,  2.1,  3.2,  4.3,  5.4,  6.5,  7.6,  8.7,  9.8, 10.9, 12. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([967., 420., 508., 556., 545.,  23.,  10.,  32.,  25.,  76.]),\n",
       " array([ 1. ,  2.1,  3.2,  4.3,  5.4,  6.5,  7.6,  8.7,  9.8, 10.9, 12. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD5CAYAAADLL+UrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAO7UlEQVR4nO3df4xeVZ3H8fdnqajgagsMBNtmi7HxR8i6sBOtkpiNVZdfsfwhGzaudt0m/YdVFBOpu5uY7G42ddeImN2waUAtkaCmsqFRVm0AYzZZiFM0KFaXBkk7UumYAv4gRhu/+8ecxqEdaGeeZ+Zx5rxfyeS599xzn/O9YfjMmfPcO01VIUnqwx+MugBJ0uIx9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOrLiZB2SfBq4EjhcVRe2trOALwDrgMeAv6iqJ5MEuAm4HHgG+OuqerCdsxn4h/a2/1xVO0829jnnnFPr1q2b4yVJUt/27t3706oam+1YTnaffpI3A78AbpsR+v8KHKmq7Um2Aauq6oYklwPvYzr03wDcVFVvaD8kJoBxoIC9wJ9W1ZPPN/b4+HhNTEzM5VolqXtJ9lbV+GzHTrq8U1XfBI4c17wJODZT3wlcNaP9tpp2P7AyyfnAnwN7qupIC/o9wKVzvxRJ0iDmu6Z/XlUdAmiv57b21cDBGf0mW9tztUuSFtGwP8jNLG31PO0nvkGyNclEkompqamhFidJvZtv6D/Rlm1or4db+ySwdka/NcDjz9N+gqraUVXjVTU+Njbr5xCSpHmab+jvBja37c3AXTPa35NpG4Cn2/LP14C3J1mVZBXw9tYmSVpEp3LL5h3AnwHnJJkEPgpsB76YZAtwALi6db+b6Tt39jN9y+Z7AarqSJJ/Ar7V+v1jVR3/4bAkaYGd9JbNUfKWTUmau4Fu2ZQkLR+GviR15KRr+kvZum1fGcm4j22/YiTjStLJONOXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0JakjA4V+kg8meTjJ95LckeRFSS5I8kCSR5J8Icnpre8L2/7+dnzdMC5AknTq5h36SVYD7wfGq+pC4DTgGuBjwI1VtR54EtjSTtkCPFlVrwRubP0kSYto0OWdFcCLk6wAzgAOAW8BdrXjO4Gr2vamtk87vjFJBhxfkjQH8w79qvox8HHgANNh/zSwF3iqqo62bpPA6ra9GjjYzj3a+p99/Psm2ZpkIsnE1NTUfMuTJM1ikOWdVUzP3i8AXg6cCVw2S9c6dsrzHPtdQ9WOqhqvqvGxsbH5lidJmsUgyztvBX5UVVNV9RvgTuBNwMq23AOwBni8bU8CawHa8ZcBRwYYX5I0R4OE/gFgQ5Iz2tr8RuD7wH3AO1ufzcBdbXt326cdv7eqTpjpS5IWziBr+g8w/YHsg8B323vtAG4Ark+yn+k1+1vbKbcCZ7f264FtA9QtSZqHFSfv8tyq6qPAR49rfhR4/Sx9fwVcPch4kqTB+ESuJHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4MFPpJVibZleQHSfYleWOSs5LsSfJIe13V+ibJp5LsT/JQkouHcwmSpFM16Ez/JuCrVfVq4HXAPmAbcE9VrQfuafsAlwHr29dW4OYBx5YkzdG8Qz/JS4E3A7cCVNWvq+opYBOws3XbCVzVtjcBt9W0+4GVSc6fd+WSpDkbZKb/CmAK+EySbye5JcmZwHlVdQigvZ7b+q8GDs44f7K1PUuSrUkmkkxMTU0NUJ4k6XiDhP4K4GLg5qq6CPglv1vKmU1maasTGqp2VNV4VY2PjY0NUJ4k6XiDhP4kMFlVD7T9XUz/EHji2LJNez08o//aGeevAR4fYHxJ0hzNO/Sr6ifAwSSvak0bge8Du4HNrW0zcFfb3g28p93FswF4+tgykCRpcawY8Pz3AbcnOR14FHgv0z9IvphkC3AAuLr1vRu4HNgPPNP6SpIW0UChX1XfAcZnObRxlr4FXDvIeJKkwfhEriR1xNCXpI4Y+pLUEUNfkjoy6N07EgDrtn1lJOM+tv2KkYwrLVXO9CWpI870taSN6jcM8LcMLU3O9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oj36S8jo7xnXdLS4Exfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JH/OcSF4D/bKGk31cDz/STnJbk20m+3PYvSPJAkkeSfCHJ6a39hW1/fzu+btCxJUlzM4zlneuAfTP2PwbcWFXrgSeBLa19C/BkVb0SuLH1kyQtooFCP8ka4ArglrYf4C3ArtZlJ3BV297U9mnHN7b+kqRFMuhM/5PAh4Hftv2zgaeq6mjbnwRWt+3VwEGAdvzp1v9ZkmxNMpFkYmpqasDyJEkzzTv0k1wJHK6qvTObZ+lap3Dsdw1VO6pqvKrGx8bG5lueJGkWg9y9cwnwjiSXAy8CXsr0zH9lkhVtNr8GeLz1nwTWApNJVgAvA44MML4kaY7mPdOvqo9U1ZqqWgdcA9xbVe8C7gPe2bptBu5q27vbPu34vVV1wkxfkrRwFuLhrBuA65PsZ3rN/tbWfitwdmu/Hti2AGNLkp7HUB7OqqpvAN9o248Cr5+lz6+Aq4cxniRpfvwzDJLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6Mu/QT7I2yX1J9iV5OMl1rf2sJHuSPNJeV7X2JPlUkv1JHkpy8bAuQpJ0agaZ6R8FPlRVrwE2ANcmeS2wDbinqtYD97R9gMuA9e1rK3DzAGNLkuZh3qFfVYeq6sG2/XNgH7Aa2ATsbN12Ale17U3AbTXtfmBlkvPnXbkkac6GsqafZB1wEfAAcF5VHYLpHwzAua3bauDgjNMmW9vx77U1yUSSiampqWGUJ0lqBg79JC8BvgR8oKp+9nxdZ2mrExqqdlTVeFWNj42NDVqeJGmGgUI/yQuYDvzbq+rO1vzEsWWb9nq4tU8Ca2ecvgZ4fJDxJUlzM8jdOwFuBfZV1SdmHNoNbG7bm4G7ZrS/p93FswF4+tgykCRpcawY4NxLgHcD303yndb2d8B24ItJtgAHgKvbsbuBy4H9wDPAewcYW5I0D/MO/ar6H2ZfpwfYOEv/Aq6d73iSpMH5RK4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSR1aMugBJ+n21bttXRjb2Y9uvWJD3daYvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6ogPZ0k6ZaN6WGmhHlTqkaEv6ffeKJ+MXW4MfWmenPVqKVr0Nf0klyb5YZL9SbYt9viS1LNFDf0kpwH/AVwGvBb4yySvXcwaJKlni72883pgf1U9CpDk88Am4PuLXIe0ZLm+rUEs9vLOauDgjP3J1iZJWgSLPdPPLG31rA7JVmBr2/1Fkh8ueFXDcQ7w01EXsYCW8/V5bUvXsr2+fGyga/uj5zqw2KE/Caydsb8GeHxmh6raAexYzKKGIclEVY2Puo6Fspyvz2tbupbz9S3UtS328s63gPVJLkhyOnANsHuRa5Ckbi3qTL+qjib5W+BrwGnAp6vq4cWsQZJ6tugPZ1XV3cDdiz3uIlhyS1JztJyvz2tbupbz9S3ItaWqTt5LkrQs+Fc2Jakjhv6AkqxNcl+SfUkeTnLdqGsatiSnJfl2ki+PupZhSrIyya4kP2j//d446pqGKckH2/fk95LckeRFo65pvpJ8OsnhJN+b0XZWkj1JHmmvq0ZZ4yCe4/r+rX1vPpTkv5KsHMZYhv7gjgIfqqrXABuAa5fhn5a4Dtg36iIWwE3AV6vq1cDrWEbXmGQ18H5gvKouZPrGiWtGW9VAPgtcelzbNuCeqloP3NP2l6rPcuL17QEurKo/Bv4P+MgwBjL0B1RVh6rqwbb9c6aDY9k8ZZxkDXAFcMuoaxmmJC8F3gzcClBVv66qp0Zb1dCtAF6cZAVwBsc9E7OUVNU3gSPHNW8CdrbtncBVi1rUEM12fVX19ao62nbvZ/q5poEZ+kOUZB1wEfDAaCsZqk8CHwZ+O+pChuwVwBTwmbZ0dUuSM0dd1LBU1Y+BjwMHgEPA01X19dFWNXTnVdUhmJ58AeeOuJ6F9DfAfw/jjQz9IUnyEuBLwAeq6mejrmcYklwJHK6qvaOuZQGsAC4Gbq6qi4BfsrSXB56lrW9vAi4AXg6cmeSvRluV5iPJ3zO9jHz7MN7P0B+CJC9gOvBvr6o7R13PEF0CvCPJY8Dngbck+dxoSxqaSWCyqo79VraL6R8Cy8VbgR9V1VRV/Qa4E3jTiGsatieSnA/QXg+PuJ6hS7IZuBJ4Vw3p/npDf0BJwvS68L6q+sSo6xmmqvpIVa2pqnVMfwh4b1Uti9liVf0EOJjkVa1pI8vrT3wfADYkOaN9j25kGX1Q3ewGNrftzcBdI6xl6JJcCtwAvKOqnhnW+xr6g7sEeDfTs+DvtK/LR12UTsn7gNuTPAT8CfAvI65naNpvMLuAB4HvMv3/+pJ9ejXJHcD/Aq9KMplkC7AdeFuSR4C3tf0l6Tmu79+BPwT2tFz5z6GM5RO5ktQPZ/qS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjvw/P+G357ZjdcsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that the test labels have the same distribution than the training labels which is a nice property for a dataset as the fitted model won't have to deal with a distribution drift."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Build the logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'l1_ratio': 0.3, 'alpha': 0.001} 0.9174713531608085\n"
     ]
    }
   ],
   "source": [
    "estimator = SGDClassifier(loss = 'log', penalty = 'elasticnet', random_state = 42)\n",
    "param_grid = {'l1_ratio':[0,0.15,0.3,0.6,0.8,1],'alpha':[0.0001,0.001,0.01]}\n",
    "\n",
    "clf = RandomizedSearchCV(estimator = estimator,param_distributions=param_grid,n_iter=5, cv=3)\n",
    "\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "best_model_LR, best_params_LR, best_score_LR = clf.best_estimator_, clf.best_params_, clf.best_score_\n",
    "\n",
    "print(best_params_LR, best_score_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Build the Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 200, 'criterion': 'entropy'} 0.9094888631389211\n"
     ]
    }
   ],
   "source": [
    "estimator = RandomForestClassifier(random_state = 42)\n",
    "param_grid = {'n_estimators':[100,150,200],'criterion':['gini','entropy']}\n",
    "\n",
    "clf = RandomizedSearchCV(estimator= estimator,param_distributions = param_grid, n_iter = 5, cv=3)\n",
    "\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "best_model_RF, best_params_RF, best_score_RF = clf.best_estimator_, clf.best_params_, clf.best_score_\n",
    "\n",
    "print(best_params_RF, best_score_RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Build the XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 250, 'max_depth': 5, 'learning_rate': 0.05, 'colsample_bylevel': 0.8} 0.9026651216685979\n"
     ]
    }
   ],
   "source": [
    "estimator = XGBClassifier(random_state = 42)\n",
    "param_grid = {'max_depth':[3,4,5,7], 'n_estimators':[100,150,200,250],'colsample_bylevel':[0.7,0.8,0.9,1],\n",
    "              'learning_rate':[0.01,0.03,0.05,0.1]}\n",
    "\n",
    "clf = RandomizedSearchCV(estimator = estimator, param_distributions = param_grid,n_iter=5, cv=3)\n",
    "\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "best_model_XG, best_params_XG, best_score_XG = clf.best_estimator_, clf.best_params_, clf.best_score_\n",
    "\n",
    "print(best_params_XG,best_score_XG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to one-hot-encode the labels in order to use the multilabel classification metrics : \n",
    "\n",
    "- The Label ranking average precision (LRAP) averages over the samples the answer to the following question: for each ground truth label, what fraction of higher-ranked labels were true labels? This performance measure will be higher if you are able to give better rank to the labels associated with each sample. The obtained score is always strictly greater than 0, and the best value is 1. If there is exactly one relevant label per sample, label ranking average precision is equivalent to the mean reciprocal rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode_array(array, nb_labels):\n",
    "    n = len(array)\n",
    "    output = np.zeros((n, nb_labels))\n",
    "    for idx in range(n):\n",
    "        output[idx, int(array[idx])-1] = 1\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label ranking for train using LR 0.973917428436545\n",
      "Label ranking for test using LR 0.938541007800971\n",
      "Label ranking for train using RF 1.0\n",
      "Label ranking for test using RF 0.9220166561248169\n",
      "Label ranking for train using XG 1.0\n",
      "Label ranking for test using XG 0.9249156651908077\n"
     ]
    }
   ],
   "source": [
    "Y_train_hot = one_hot_encode_array(Y_train, 12)\n",
    "Y_test_hot = one_hot_encode_array(Y_test, 12)\n",
    "\n",
    "pred_train_LR = best_model_LR.predict(X_train)\n",
    "pred_test_LR = best_model_LR.predict(X_test)\n",
    "\n",
    "pred_train_RF = best_model_RF.predict(X_train)\n",
    "pred_test_RF = best_model_RF.predict(X_test)\n",
    "\n",
    "pred_train_XG = best_model_XG.predict(X_train)\n",
    "pred_test_XG = best_model_XG.predict(X_test)\n",
    "\n",
    "pred_train_LR_hot = one_hot_encode_array(pred_train_LR, 12)\n",
    "pred_test_LR_hot = one_hot_encode_array(pred_test_LR, 12)\n",
    "\n",
    "pred_train_RF_hot = one_hot_encode_array(pred_train_RF, 12)\n",
    "pred_test_RF_hot = one_hot_encode_array(pred_test_RF, 12)\n",
    "\n",
    "pred_train_XG_hot = one_hot_encode_array(pred_train_XG, 12)\n",
    "pred_test_XG_hot = one_hot_encode_array(pred_test_XG, 12)\n",
    "\n",
    "\n",
    "print(\"Label ranking for train using LR\", label_ranking_average_precision_score(Y_train_hot, pred_train_LR_hot))\n",
    "print(\"Label ranking for test using LR\", label_ranking_average_precision_score(Y_test_hot, pred_test_LR_hot))\n",
    "\n",
    "print(\"Label ranking for train using RF\", label_ranking_average_precision_score(Y_train_hot, pred_train_RF_hot))\n",
    "print(\"Label ranking for test using RF\", label_ranking_average_precision_score(Y_test_hot, pred_test_RF_hot))\n",
    "\n",
    "print(\"Label ranking for train using XG\", label_ranking_average_precision_score(Y_train_hot, pred_train_XG_hot))\n",
    "print(\"Label ranking for test using XG\", label_ranking_average_precision_score(Y_test_hot, pred_test_XG_hot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardisation des variables predictives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardise(array):\n",
    "    return (array - np.mean(array, axis=0)) / np.std(array, axis=0)\n",
    "\n",
    "X_train_standard = standardise(X_train)\n",
    "X_test_standard = standardise(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'l1_ratio': 0.3, 'alpha': 0.001} 0.9125788592764259\n",
      "{'n_estimators': 200, 'criterion': 'entropy'} 0.9093601132998583\n",
      "{'n_estimators': 120, 'max_depth': 5, 'learning_rate': 0.05, 'colsample_bylevel': 1} 0.8958413801982748\n"
     ]
    }
   ],
   "source": [
    "#SGD\n",
    "\n",
    "estimator = SGDClassifier(loss = 'log', penalty = 'elasticnet', random_state = 42)\n",
    "param_grid = {'l1_ratio':[0,0.15,0.3,0.6,0.8,1],'alpha':[0.0001,0.001,0.01]}\n",
    "\n",
    "clf = RandomizedSearchCV(estimator = estimator,param_distributions=param_grid,n_iter=5, cv=3)\n",
    "\n",
    "clf.fit(X_train_standard, Y_train)\n",
    "\n",
    "best_model_LR_std, best_params_LR_std, best_score_LR_std = clf.best_estimator_, clf.best_params_, clf.best_score_\n",
    "\n",
    "print(best_params_LR_std, best_score_LR_std)\n",
    "\n",
    "#RF\n",
    "\n",
    "estimator = RandomForestClassifier(random_state = 42)\n",
    "param_grid = {'n_estimators':[100,150,200],'criterion':['gini','entropy']}\n",
    "\n",
    "clf = RandomizedSearchCV(estimator= estimator,param_distributions = param_grid, n_iter = 5, cv=3)\n",
    "\n",
    "clf.fit(X_train_standard, Y_train)\n",
    "\n",
    "best_model_RF_std, best_params_RF_std, best_score_RF_std = clf.best_estimator_, clf.best_params_, clf.best_score_\n",
    "\n",
    "print(best_params_RF_std, best_score_RF_std)\n",
    "\n",
    "#XG\n",
    "\n",
    "estimator = XGBClassifier(random_state = 42)\n",
    "param_grid = {'max_depth':[3,4,5,7], 'n_estimators':[100,120,150],'colsample_bylevel':[0.7,0.8,0.9,1],\n",
    "              'learning_rate':[0.01,0.03,0.05,0.1]}\n",
    "\n",
    "clf = RandomizedSearchCV(estimator = estimator, param_distributions = param_grid,n_iter=2, cv=3)\n",
    "\n",
    "clf.fit(X_train_standard, Y_train)\n",
    "\n",
    "best_model_XG_std, best_params_XG_std, best_score_XG_std = clf.best_estimator_, clf.best_params_, clf.best_score_\n",
    "\n",
    "print(best_params_XG_std,best_score_XG_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label ranking for train using LR 0.9753336766662349\n",
      "Label ranking for test using LR 0.9272348724436014\n",
      "Label ranking for train using RF 1.0\n",
      "Label ranking for test using RF 0.9144792325532388\n",
      "Label ranking for train using XG 1.0\n",
      "Label ranking for test using XG 0.9179580434324285\n"
     ]
    }
   ],
   "source": [
    "pred_train_LR_std = best_model_LR_std.predict(X_train_standard)\n",
    "pred_test_LR_std = best_model_LR_std.predict(X_test_standard)\n",
    "\n",
    "pred_train_RF_std = best_model_RF_std.predict(X_train_standard)\n",
    "pred_test_RF_std = best_model_RF_std.predict(X_test_standard)\n",
    "\n",
    "pred_train_XG_std = best_model_XG_std.predict(X_train_standard)\n",
    "pred_test_XG_std = best_model_XG_std.predict(X_test_standard)\n",
    "\n",
    "pred_train_LR_std_hot = one_hot_encode_array(pred_train_LR_std, 12)\n",
    "pred_test_LR_std_hot = one_hot_encode_array(pred_test_LR_std, 12)\n",
    "\n",
    "pred_train_RF_std_hot = one_hot_encode_array(pred_train_RF_std, 12)\n",
    "pred_test_RF_std_hot = one_hot_encode_array(pred_test_RF_std, 12)\n",
    "\n",
    "pred_train_XG_std_hot = one_hot_encode_array(pred_train_XG_std, 12)\n",
    "pred_test_XG_std_hot = one_hot_encode_array(pred_test_XG_std, 12)\n",
    "\n",
    "\n",
    "print(\"Label ranking for train using LR\", label_ranking_average_precision_score(Y_train_hot, pred_train_LR_std_hot))\n",
    "print(\"Label ranking for test using LR\", label_ranking_average_precision_score(Y_test_hot, pred_test_LR_std_hot))\n",
    "\n",
    "print(\"Label ranking for train using RF\", label_ranking_average_precision_score(Y_train_hot, pred_train_RF_std_hot))\n",
    "print(\"Label ranking for test using RF\", label_ranking_average_precision_score(Y_test_hot, pred_test_RF_std_hot))\n",
    "\n",
    "print(\"Label ranking for train using XG\", label_ranking_average_precision_score(Y_train_hot, pred_train_XG_std_hot))\n",
    "print(\"Label ranking for test using XG\", label_ranking_average_precision_score(Y_test_hot, pred_test_XG_std_hot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduction de la dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=20)\n",
    "\n",
    "pca.fit(X_train_standard)\n",
    "\n",
    "X_train_pca = pca.transform(X_train_standard)\n",
    "X_test_pca = pca.transform(X_test_standard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'l1_ratio': 0.6, 'alpha': 0.0001} 0.8424101969872537\n",
      "{'n_estimators': 150, 'criterion': 'gini'} 0.8179477275653405\n",
      "{'n_estimators': 250, 'max_depth': 4, 'learning_rate': 0.05, 'colsample_bylevel': 1} 0.8227114716106605\n"
     ]
    }
   ],
   "source": [
    "#SGD\n",
    "\n",
    "estimator = SGDClassifier(loss = 'log', penalty = 'elasticnet', random_state = 42)\n",
    "param_grid = {'l1_ratio':[0,0.15,0.3,0.6,0.8,1],'alpha':[0.0001,0.001,0.01]}\n",
    "\n",
    "clf = RandomizedSearchCV(estimator = estimator,param_distributions=param_grid,n_iter=5, cv=3)\n",
    "\n",
    "clf.fit(X_train_pca, Y_train)\n",
    "\n",
    "best_model_LR_pca, best_params_LR_pca, best_score_LR_pca = clf.best_estimator_, clf.best_params_, clf.best_score_\n",
    "\n",
    "print(best_params_LR_pca, best_score_LR_pca)\n",
    "\n",
    "#RF\n",
    "\n",
    "estimator = RandomForestClassifier(random_state = 42)\n",
    "param_grid = {'n_estimators':[100,150,200],'criterion':['gini','entropy']}\n",
    "\n",
    "clf = RandomizedSearchCV(estimator= estimator,param_distributions = param_grid, n_iter = 5, cv=3)\n",
    "\n",
    "clf.fit(X_train_pca, Y_train)\n",
    "\n",
    "best_model_RF_pca, best_params_RF_pca, best_score_RF_pca = clf.best_estimator_, clf.best_params_, clf.best_score_\n",
    "\n",
    "print(best_params_RF_pca, best_score_RF_pca)\n",
    "\n",
    "#XG\n",
    "\n",
    "estimator = XGBClassifier(random_state = 42)\n",
    "param_grid = {'max_depth':[3,4,5,7], 'n_estimators':[100,150,200,250],'colsample_bylevel':[0.7,0.8,0.9,1],\n",
    "              'learning_rate':[0.01,0.03,0.05,0.1]}\n",
    "\n",
    "clf = RandomizedSearchCV(estimator = estimator, param_distributions = param_grid,n_iter=5, cv=3)\n",
    "\n",
    "clf.fit(X_train_pca, Y_train)\n",
    "\n",
    "best_model_XG_pca, best_params_XG_pca, best_score_XG_pca = clf.best_estimator_, clf.best_params_, clf.best_score_\n",
    "\n",
    "print(best_params_XG_pca,best_score_XG_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label ranking for train using LR 0.8911849276855013\n",
      "Label ranking for test using LR 0.8651960784313745\n",
      "Label ranking for train using RF 1.0\n",
      "Label ranking for test using RF 0.8515707358212139\n",
      "Label ranking for train using XG 0.9759237800952725\n",
      "Label ranking for test using XG 0.8579485557663964\n"
     ]
    }
   ],
   "source": [
    "pred_train_LR_pca = best_model_LR_pca.predict(X_train_pca)\n",
    "pred_test_LR_pca = best_model_LR_pca.predict(X_test_pca)\n",
    "\n",
    "pred_train_RF_pca = best_model_RF_pca.predict(X_train_pca)\n",
    "pred_test_RF_pca = best_model_RF_pca.predict(X_test_pca)\n",
    "\n",
    "pred_train_XG_pca = best_model_XG_pca.predict(X_train_pca)\n",
    "pred_test_XG_pca = best_model_XG_pca.predict(X_test_pca)\n",
    "\n",
    "pred_train_LR_pca_hot = one_hot_encode_array(pred_train_LR_pca, 12)\n",
    "pred_test_LR_pca_hot = one_hot_encode_array(pred_test_LR_pca, 12)\n",
    "\n",
    "pred_train_RF_pca_hot = one_hot_encode_array(pred_train_RF_pca, 12)\n",
    "pred_test_RF_pca_hot = one_hot_encode_array(pred_test_RF_pca, 12)\n",
    "\n",
    "pred_train_XG_pca_hot = one_hot_encode_array(pred_train_XG_pca, 12)\n",
    "pred_test_XG_pca_hot = one_hot_encode_array(pred_test_XG_pca, 12)\n",
    "\n",
    "\n",
    "print(\"Label ranking for train using LR\", label_ranking_average_precision_score(Y_train_hot, pred_train_LR_pca_hot))\n",
    "print(\"Label ranking for test using LR\", label_ranking_average_precision_score(Y_test_hot, pred_test_LR_pca_hot))\n",
    "\n",
    "print(\"Label ranking for train using RF\", label_ranking_average_precision_score(Y_train_hot, pred_train_RF_pca_hot))\n",
    "print(\"Label ranking for test using RF\", label_ranking_average_precision_score(Y_test_hot, pred_test_RF_pca_hot))\n",
    "\n",
    "print(\"Label ranking for train using XG\", label_ranking_average_precision_score(Y_train_hot, pred_train_XG_pca_hot))\n",
    "print(\"Label ranking for test using XG\", label_ranking_average_precision_score(Y_test_hot, pred_test_XG_pca_hot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choix du meilleur modele"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le meilleur modele est : la logistique regression appliquee sur les donnees sans standardisation ni reduction de la dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Django"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
